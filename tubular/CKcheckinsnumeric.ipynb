{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057c95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add your local path\n",
    "sys.path.append('/workspaces/tubular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1be5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import narwhals as nw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from tubular.base import BaseTransformer, DataFrameMethodTransformer\n",
    "from tubular.mixins import (\n",
    "    CheckNumericMixin,\n",
    "    DropOriginalMixin,\n",
    "    NewColumnNameMixin,\n",
    "    TwoColumnMixin,\n",
    ")\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from narwhals.typing import (\n",
    "        FrameT,\n",
    "        IntoSeriesT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44f3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseNumericTransformer(BaseTransformer, CheckNumericMixin):\n",
    "    \"\"\"\n",
    "    Extends BaseTransformer for datetime scenarios.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : List[str]\n",
    "        List of columns to be operated on.\n",
    "\n",
    "    **kwargs\n",
    "        Arbitrary keyword arguments passed onto BaseTransformer.init method.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    columns : List[str]\n",
    "        List of columns to be operated on\n",
    "\n",
    "    polars_compatible : bool\n",
    "        class attribute, indicates whether transformer has been converted to polars/pandas agnostic narwhals framework\n",
    "    FITS: bool\n",
    "        class attribute, indicates whether transform requires fit to be run first\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    polars_compatible = True\n",
    "\n",
    "    FITS = False\n",
    "\n",
    "    def __init__(self, columns: list[str], **kwargs: dict[str, bool]) -> None:\n",
    "        super().__init__(columns=columns, **kwargs)\n",
    "\n",
    "    @nw.narwhalify\n",
    "    def fit(\n",
    "        self,\n",
    "        X: FrameT,\n",
    "        y: nw.Series | None = None,\n",
    "    ) -> BaseNumericTransformer:\n",
    "        \"\"\"Base fit method. Validates data and attributes prior to the child objects fit logic.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd/pl.DataFrame\n",
    "            A dataframe containing the required columns\n",
    "\n",
    "        y : pd/pl.Series | None\n",
    "            Required for pipeline.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().fit(X, y)\n",
    "\n",
    "        CheckNumericMixin.check_numeric_columns(self, X[self.columns])\n",
    "\n",
    "        return self\n",
    "\n",
    "    @nw.narwhalify\n",
    "    def transform(self, X: FrameT) -> FrameT:\n",
    "        \"\"\"Base transform method. Validates data and attributes prior to the child objects tranform logic.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd/pl.DataFrame\n",
    "            Data to transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : pd/pl.DataFrame\n",
    "            Validated data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        X = super().transform(X)\n",
    "\n",
    "        CheckNumericMixin.check_numeric_columns(self, X[self.columns])\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc5824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "df = iris.data\n",
    "df = pl.DataFrame(df).select('column_0').rename({'column_0':'a'})\n",
    "df = nw.from_native(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc62402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 1, 3, 1, 0, 3, 0, 3, 2, 1, 2, 2, 0, 3, 3, 0, 1,\n",
       "       0, 0, 3, 0, 0, 3, 3, 3, 3, 1, 1, 1, 3, 0, 0, 0, 0, 3, 0, 3, 1, 3,\n",
       "       0, 0, 0, 3, 0, 2, 0, 0, 0, 3, 2, 0, 3, 0, 1, 3, 3, 4, 2, 4, 1, 1,\n",
       "       3, 3, 1, 0, 0, 3, 3, 4, 4, 3, 1, 0, 4, 3, 1, 1, 3, 3, 3, 1, 4, 4,\n",
       "       3, 3, 3, 4, 3, 3, 3, 1, 1, 1, 0, 1, 1, 1, 3, 3, 3, 0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee028fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = kmeans.predict(df)\n",
    "groups = nw.from_native(pl.DataFrame(groups)).rename({'column_0':'groups'})\n",
    "groups = groups.with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6f7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = nw.from_native(df)\n",
    "df2 = df2.with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50e4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df2.join(groups, on = 'index')\n",
    "bins_max = results.group_by('groups').agg(\n",
    "    nw.col('a').max()\n",
    "    ).sort(\"a\").select('a').to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9879d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.2, 5.9, 6.5, 7.2, 7.9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "389dc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneDKmeansTransformer(BaseNumericTransformer, DropOriginalMixin):\n",
    "    \"\"\"Transformer that generates a new column based on kmeans algorithm.\n",
    "    Transformer runs the kmean algorithm based on given number of clusters and then identifies the bins' cuts based on the results.\n",
    "    Finally it passes them into the a cut function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    column : str\n",
    "        Name of the column to discretise.\n",
    "\n",
    "    new_column_name : str\n",
    "        Name given to the new discrete column.\n",
    "\n",
    "    n_clusters : int, default = 8\n",
    "        The number of clusters to form as well as the number of centroids to generate.\n",
    "\n",
    "    n_init \"auto\" or int, default=\"auto\"\n",
    "        Number of times the k-means algorithm is run with different centroid seeds.\n",
    "        The final results is the best output of n_init consecutive runs in terms of inertia.\n",
    "        Several runs are recommended for sparse high-dimensional problems (see `Clustering sparse data with k-means <https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#kmeans-sparse-high-dim>`__).\n",
    "\n",
    "        When n_init='auto', the number of runs depends on the value of init: 10 if using init='random' or init is a callable;\n",
    "        1 if using init='k-means++' or init is an array-like.\n",
    "\n",
    "    drop_original : bool, default=False\n",
    "        Should the original columns to be transformed be dropped after applying the\n",
    "        OneDKmeanstransformer?\n",
    "\n",
    "    kmeans_kwargs : dict, default = {}\n",
    "        A dictionary of keyword arguments to be passed to the sklearn KMeans method when it is called in fit.\n",
    "\n",
    "    **kwargs\n",
    "        Arbitrary keyword arguments passed onto BaseTransformer.init().\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    polars_compatible : bool\n",
    "        class attribute, indicates whether transformer has been converted to polars/pandas agnostic narwhals framework\n",
    "    FITS: bool\n",
    "        class attribute, indicates whether transform requires fit to be run first\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    polars_compatible = True\n",
    "\n",
    "    FITS = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        column: str,\n",
    "        new_column_name: str,\n",
    "        n_init: str | int = \"auto\",\n",
    "        n_clusters: int = 8,\n",
    "        drop_original: bool = False,\n",
    "        kmeans_kwargs: dict[str, object] | None = None,\n",
    "        **kwargs: dict[str, bool],\n",
    "    ) -> None:\n",
    "        if not isinstance(new_column_name, str):\n",
    "            msg = f\"{self.classname()}: new_column_name should be a str but got type {type(new_column_name)}\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if not isinstance(column, str):\n",
    "            msg = f\"{self.classname()}: column arg should be a single str giving the column to group.\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if not isinstance(n_clusters, int):\n",
    "            msg = f\"{self.classname()}: n_clusters should be a int but got type {type(n_clusters)}\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if not (n_init == \"auto\" or isinstance(n_init, int)):\n",
    "            msg = f\"{self.classname()}: n_init should be 'auto' or int but got type {type(n_init)}\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if kmeans_kwargs is None:\n",
    "            kmeans_kwargs = {}\n",
    "        else:\n",
    "            if type(kmeans_kwargs) is not dict:\n",
    "                msg = f\"{self.classname()}: kmeans_kwargs should be a dict but got type {type(kmeans_kwargs)}\"\n",
    "                raise TypeError(msg)\n",
    "\n",
    "        for i, k in enumerate(kmeans_kwargs.keys()):\n",
    "            if type(k) is not str:\n",
    "                msg = f\"{self.classname()}: unexpected type ({type(k)}) for kmeans_kwargs key in position {i}, must be str\"\n",
    "                raise TypeError(msg)\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.new_column_name = new_column_name\n",
    "        self.n_init = n_init\n",
    "        self.kmeans_kwargs = kmeans_kwargs\n",
    "\n",
    "        # This attribute is not for use in any method, use 'columns' instead.\n",
    "        # Here only as a fix to allow string representation of transformer.\n",
    "        self.column = column\n",
    "\n",
    "        super().__init__(columns=[column], **kwargs)\n",
    "        self.set_drop_original_column(drop_original)\n",
    "\n",
    "    @nw.narwhalify\n",
    "    def fit(self, X: FrameT, y: IntoSeriesT | None = None) -> OneDKmeansTransformer:\n",
    "        \"\"\"Fir transformer to input data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd/pl.DataFrame\n",
    "            Dataframe with columns to learn scaling values from.\n",
    "\n",
    "        y : None\n",
    "            Required for pipeline.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().fit(X, y)\n",
    "\n",
    "        #X = nw.from_native(X)\n",
    "\n",
    "        # Check that X does not contain Nans and return ValueError.\n",
    "        if (\n",
    "            X.select(nw.col(self.columns[0]).is_null().any()).to_numpy().ravel()[0]\n",
    "            or X.select(nw.col(self.columns[0]).is_nan().any()).to_numpy().ravel()[0]\n",
    "        ):\n",
    "            msg = f\"{self.classname()}: X should not contain missing values.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=self.n_clusters,\n",
    "            n_init=self.n_init,\n",
    "            copy_x=False,\n",
    "            **self.kmeans_kwargs,\n",
    "        )\n",
    "\n",
    "        native_namespace = nw.get_native_namespace(X).__name__\n",
    "        groups = kmeans.fit_predict(X.select(self.columns[0]).to_native())\n",
    "        print(groups)\n",
    "\n",
    "        X = X.with_columns(\n",
    "            nw.new_series(\n",
    "                name=\"groups\",\n",
    "                values=groups,\n",
    "                backend=native_namespace,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            X.group_by(\"groups\")\n",
    "            .agg(\n",
    "                nw.col(self.columns[0]).max(),\n",
    "            )\n",
    "            .sort(self.columns[0])\n",
    "            .select(self.columns[0])\n",
    "            .to_numpy()\n",
    "            .ravel()\n",
    "        )\n",
    "        self.bins = (\n",
    "            X.group_by(\"groups\")\n",
    "            .agg(\n",
    "                nw.col(self.columns[0]).max(),\n",
    "            )\n",
    "            .sort(self.columns[0])\n",
    "            .select(self.columns[0])\n",
    "            .to_numpy()\n",
    "            .ravel()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    @nw.narwhalify\n",
    "    def transform(self, X: FrameT) -> FrameT:\n",
    "        \"\"\"Generate from input pd/pl.DataFrame (X) bins based on Kmeans results and add this column or columns in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pl/pd.DataFrame\n",
    "            Data to transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : pl/pd.DataFrame\n",
    "            Input X with additional cluster column added.\n",
    "        \"\"\"\n",
    "        X = super().transform(X)\n",
    "\n",
    "        X = nw.from_native(X)\n",
    "        native_namespace = nw.get_native_namespace(X).__name__\n",
    "\n",
    "        groups = np.digitize(\n",
    "            X.select(self.column[0]).to_numpy().ravel(),\n",
    "            bins=self.bins,\n",
    "            right=True,\n",
    "        )\n",
    "\n",
    "        X = X.with_columns(\n",
    "            nw.new_series(\n",
    "                name=self.new_column_name,\n",
    "                values=groups,\n",
    "                backend=native_namespace,\n",
    "            ),\n",
    "        )\n",
    "        return self.drop_original_column(X, self.drop_original, self.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a70d26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'a': [4, 5, 4, 5, 2, 1, 3, 2, 1, 5, 10, 12, 4, 16, 17],\n",
    "    'b': [43, -77, -61, 29, 84, 29, -24, 40, 84, -96, 10, -4, 15, -12, 15],\n",
    "    'c': [\"a\", \"b\", \"a\", \"b\", \"a\", \"b\", \"b\", \"a\", \"c\", \"b\", \"a\", \"c\", \"a\", \"c\", \"a\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7ca4adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 2 0 3 0 2 1 4 3 4 3 4]\n",
      "[-61  -4  15  43  84]\n",
      "shape: (15, 4)\n",
      "┌─────┬─────┬─────┬─────┐\n",
      "│ a   ┆ b   ┆ c   ┆ new │\n",
      "│ --- ┆ --- ┆ --- ┆ --- │\n",
      "│ i64 ┆ i64 ┆ str ┆ i64 │\n",
      "╞═════╪═════╪═════╪═════╡\n",
      "│ 4   ┆ 43  ┆ a   ┆ 3   │\n",
      "│ 5   ┆ -77 ┆ b   ┆ 0   │\n",
      "│ 4   ┆ -61 ┆ a   ┆ 0   │\n",
      "│ 5   ┆ 29  ┆ b   ┆ 3   │\n",
      "│ 2   ┆ 84  ┆ a   ┆ 4   │\n",
      "│ …   ┆ …   ┆ …   ┆ …   │\n",
      "│ 10  ┆ 10  ┆ a   ┆ 2   │\n",
      "│ 12  ┆ -4  ┆ c   ┆ 1   │\n",
      "│ 4   ┆ 15  ┆ a   ┆ 2   │\n",
      "│ 16  ┆ -12 ┆ c   ┆ 1   │\n",
      "│ 17  ┆ 15  ┆ a   ┆ 2   │\n",
      "└─────┴─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(df_dict)\n",
    "kmeans = OneDKmeansTransformer(column='b', n_clusters=5, new_column_name='new', drop_original=False, kmeans_kwargs={\"random_state\":42}).fit(X=df)\n",
    "df = kmeans.transform(df)\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27b08455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b\n",
      "0  4  43\n",
      "1  5  77\n",
      "2  4  61\n",
      "3  5  29\n",
      "4  2  84\n",
      "5  1  29\n",
      "6  3  24\n",
      "7  2  40\n",
      "8  1  84\n",
      "9  5  96\n",
      "[0 1 0 0 1 0 0 0 1 1]\n",
      "[61 96]\n",
      "   a   b  new\n",
      "0  4  43    0\n",
      "1  5  77    1\n",
      "2  4  61    0\n",
      "3  5  29    0\n",
      "4  2  84    1\n",
      "5  1  29    0\n",
      "6  3  24    0\n",
      "7  2  40    0\n",
      "8  1  84    1\n",
      "9  5  96    1\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(df_dict)\n",
    "print(df2)\n",
    "kmeans = OneDKmeansTransformer(column='b', n_clusters=2, new_column_name='new', drop_original=False, kmeans_kwargs={\"random_state\":42}).fit(X=df2)\n",
    "df2 = kmeans.transform(df2)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc902f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
