{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057c95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add your local path\n",
    "sys.path.append('/workspaces/tubular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1be5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import narwhals as nw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from tubular.base import BaseTransformer, DataFrameMethodTransformer\n",
    "from tubular.mixins import (\n",
    "    CheckNumericMixin,\n",
    "    DropOriginalMixin,\n",
    "    NewColumnNameMixin,\n",
    "    TwoColumnMixin,\n",
    ")\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from narwhals.typing import (\n",
    "        FrameT,\n",
    "        IntoSeriesT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44f3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseNumericTransformer(BaseTransformer, CheckNumericMixin):\n",
    "    \"\"\"\n",
    "    Extends BaseTransformer for datetime scenarios.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : List[str]\n",
    "        List of columns to be operated on.\n",
    "\n",
    "    **kwargs\n",
    "        Arbitrary keyword arguments passed onto BaseTransformer.init method.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    columns : List[str]\n",
    "        List of columns to be operated on\n",
    "\n",
    "    polars_compatible : bool\n",
    "        class attribute, indicates whether transformer has been converted to polars/pandas agnostic narwhals framework\n",
    "    FITS: bool\n",
    "        class attribute, indicates whether transform requires fit to be run first\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    polars_compatible = True\n",
    "\n",
    "    FITS = False\n",
    "\n",
    "    def __init__(self, columns: list[str], **kwargs: dict[str, bool]) -> None:\n",
    "        super().__init__(columns=columns, **kwargs)\n",
    "\n",
    "    @nw.narwhalify\n",
    "    def fit(\n",
    "        self,\n",
    "        X: FrameT,\n",
    "        y: nw.Series | None = None,\n",
    "    ) -> BaseNumericTransformer:\n",
    "        \"\"\"Base fit method. Validates data and attributes prior to the child objects fit logic.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd/pl.DataFrame\n",
    "            A dataframe containing the required columns\n",
    "\n",
    "        y : pd/pl.Series | None\n",
    "            Required for pipeline.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().fit(X, y)\n",
    "\n",
    "        CheckNumericMixin.check_numeric_columns(self, X[self.columns])\n",
    "\n",
    "        return self\n",
    "\n",
    "    @nw.narwhalify\n",
    "    def transform(self, X: FrameT) -> FrameT:\n",
    "        \"\"\"Base transform method. Validates data and attributes prior to the child objects tranform logic.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd/pl.DataFrame\n",
    "            Data to transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : pd/pl.DataFrame\n",
    "            Validated data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        X = super().transform(X)\n",
    "\n",
    "        CheckNumericMixin.check_numeric_columns(self, X[self.columns])\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fc5824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "df = iris.data\n",
    "df = pl.DataFrame(df).select('column_0').rename({'column_0':'a'})\n",
    "df = nw.from_native(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc62402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 0, 1, 4, 1, 2, 1, 2, 4, 0, 1, 0, 0, 4, 4, 4, 2, 1,\n",
       "       2, 2, 4, 2, 4, 4, 4, 4, 4, 1, 1, 1, 4, 2, 2, 2, 2, 4, 2, 4, 1, 4,\n",
       "       2, 2, 2, 4, 2, 0, 2, 2, 2, 4, 0, 2, 4, 2, 1, 4, 1, 3, 0, 3, 1, 3,\n",
       "       1, 4, 1, 2, 2, 4, 1, 3, 3, 4, 1, 2, 3, 4, 1, 3, 4, 4, 4, 3, 3, 3,\n",
       "       4, 4, 4, 3, 4, 4, 4, 1, 1, 1, 2, 1, 1, 1, 4, 1, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bee028fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = kmeans.predict(df)\n",
    "groups = nw.from_native(pl.DataFrame(groups)).rename({'column_0':'groups'})\n",
    "groups = groups.with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae6f7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = nw.from_native(df)\n",
    "df2 = df2.with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e50e4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df2.join(groups, on = 'index')\n",
    "bins_max = results.group_by('groups').agg(\n",
    "    nw.col('a').max()\n",
    "    ).sort(\"a\").select('a').to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9879d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.2, 5.8, 6.4, 7.1, 7.9])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389dc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.7 5.1 5.5 5.9 6.2 6.7 7.3 7.9]\n",
      "[4.6 4.9 5.2 5.6 6.1 6.6 7.2 7.9]\n"
     ]
    }
   ],
   "source": [
    "class OneDKmeansTransformer(BaseNumericTransformer):\n",
    "    \"\"\"Transformer that generates a new column based on kmeans algorithm.\n",
    "    Transformer runs the kmean algorithm based on given number of clusters and then identifies the bins' cuts based on the results.\n",
    "    Finally it passes them into the a cut function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    column : str\n",
    "        Name of the column to discretise.\n",
    "\n",
    "    new_column_name : str\n",
    "        Name given to the new discrete column.\n",
    "\n",
    "    n_clusters : int, default = 8\n",
    "        The number of clusters to form as well as the number of centroids to generate.\n",
    "\n",
    "    n_init \"auto\" or int, default=\"auto\"\n",
    "        Number of times the k-means algorithm is run with different centroid seeds. \n",
    "        The final results is the best output of n_init consecutive runs in terms of inertia. \n",
    "        Several runs are recommended for sparse high-dimensional problems (see `Clustering sparse data with k-means <https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#kmeans-sparse-high-dim>`__).\n",
    "\n",
    "        When n_init='auto', the number of runs depends on the value of init: 10 if using init='random' or init is a callable; \n",
    "        1 if using init='k-means++' or init is an array-like.\n",
    "\n",
    "    **kwargs\n",
    "        Arbitrary keyword arguments passed onto BaseTransformer.init().\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    polars_compatible : bool\n",
    "        class attribute, indicates whether transformer has been converted to polars/pandas agnostic narwhals framework\n",
    "    FITS: bool\n",
    "        class attribute, indicates whether transform requires fit to be run first\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    polars_compatible = True\n",
    "\n",
    "    FITS = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        column: str,\n",
    "        new_column_name: str,\n",
    "        n_init: str | int = 'auto',\n",
    "        n_clusters: int = 8,\n",
    "        **kwargs: dict[str, bool],\n",
    "    ) -> None:\n",
    "        if not isinstance(new_column_name, str):\n",
    "            msg = f\"{self.classname()}: new_column_name should be a str but got type {type(new_column_name)}\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if not isinstance(n_clusters, int):\n",
    "            msg = f\"{self.classname()}: n_clusters should be a str but got type {type(n_clusters)}\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if not (n_init==\"auto\" or isinstance(n_init, int)):\n",
    "            msg = f\"{self.classname()}: n_init should be 'auto' or int but got type {type(n_init)}\"\n",
    "            raise TypeError(msg)   \n",
    "                \n",
    "        self.n_clusters = n_clusters\n",
    "        self.new_column_name = new_column_name\n",
    "        self.n_init = n_init\n",
    "\n",
    "        super().__init__(columns=column, **kwargs)\n",
    "\n",
    "    def fit(self, X: FrameT, y: IntoSeriesT | None = None) -> OneDKmeansTransformer:\n",
    "        \"\"\"Fir transformer to input data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd/pl.DataFrame\n",
    "            Dataframe with columns to learn scaling values from.\n",
    "\n",
    "        y : None\n",
    "            Required for pipeline.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().fit(X, y)\n",
    "\n",
    "        X = nw.from_native(X)\n",
    "\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=self.n_clusters,\n",
    "            n_init=self.n_init,\n",
    "        )\n",
    "\n",
    "        groups = kmeans.fit_predict(X.select(self.columns))\n",
    "        if  nw.get_native_namespace(X).__name__ == \"pandas\":\n",
    "            groups = nw.from_native(pd.DataFrame(groups)).rename({0:'groups'})\n",
    "        if  nw.get_native_namespace(X).__name__ == \"polars\":\n",
    "            groups = nw.from_native(pl.DataFrame(groups)).rename({'column_0':'groups'})\n",
    "        groups = groups.with_row_index()\n",
    "        \n",
    "        results = X.with_row_index().join(groups, on = 'index')\n",
    "        bins_max = results.group_by('groups').agg(\n",
    "            nw.col('a').max()\n",
    "            ).sort(\"a\").select('a').to_numpy().ravel()\n",
    "\n",
    "        return bins_max\n",
    "    \n",
    "    def transform(self, X : FrameT) -> FrameT:\n",
    "        X = super().transform(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "iris = datasets.load_iris()\n",
    "df = iris.data\n",
    "df = pl.DataFrame(df).select('column_0').rename({'column_0':'a'})\n",
    "bins = OneDKmeansTransformer(column='a', new_column_name='new').fit(X=df)\n",
    "print(bins)\n",
    "\n",
    "df = pd.DataFrame(df).rename(columns={0:'a'})\n",
    "bins = OneDKmeansTransformer(column='a', new_column_name='new').fit(X=df)\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2a3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
